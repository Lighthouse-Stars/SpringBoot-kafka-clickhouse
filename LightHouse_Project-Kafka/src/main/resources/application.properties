#服务器地址
spring.kafka.bootstrap-servers=192.168.131.131:9092 


#生产者配置：
# 重试次数
spring.kafka.producer.retries=0
# 应答级别:多好个分区副本备份完成时向生产者发送ack确认
spring.kafka.producer.acks=1
# 批量大小
spring.kafka.producer.batch-size=16384

# 生产端缓冲区大小
spring.kafka.producer.buffer-memory=33554432
# 注册生产者的Key和Value的序列化器
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer


#消费者配置
# 指定consumer的group.id
spring.kafka.consumer.group-id=test-consumer-group
# 是否自动提交offset
spring.kafka.consumer.enable-auto-commit=true
# 提交offset延时(接收到消息后多久提交offset)
spring.kafka.consumer.auto.commit.interval.ms=1000


# 当kafka中没有初始offset或offset超出范围时将自动重置offset
# earliest:重置为分区中最小的offset;
# latest:重置为分区中最新的offset(消费分区中新产生的数据);
# none:只要有一个分区不存在已提交的offset,就抛出异常;

spring.kafka.consumer.auto-offset-reset=latest
# 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
spring.kafka.consumer.properties.session.timeout.ms=120000
# 消费请求超时时间
spring.kafka.consumer.properties.request.timeout.ms=180000
# 注册消费者的反序列化器
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#监听接口主题不存在时报错，设置关闭
spring.kafka.listener.missing-topics-fatal=false
